{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DHS in-country cross-validated model results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports-and-Constants\" data-toc-modified-id=\"Imports-and-Constants-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports and Constants</a></span></li><li><span><a href=\"#Load-Saved-Data\" data-toc-modified-id=\"Load-Saved-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load Saved Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-labels,-locs,-and-years\" data-toc-modified-id=\"Load-labels,-locs,-and-years-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Load <code>labels</code>, <code>locs</code>, and <code>years</code></a></span></li><li><span><a href=\"#Load-loc_dict\" data-toc-modified-id=\"Load-loc_dict-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Load <code>loc_dict</code></a></span></li><li><span><a href=\"#Get-urban-v.-rural-indices\" data-toc-modified-id=\"Get-urban-v.-rural-indices-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Get urban v. rural indices</a></span></li><li><span><a href=\"#country_indices-and-country_labels\" data-toc-modified-id=\"country_indices-and-country_labels-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span><code>country_indices</code> and <code>country_labels</code></a></span></li></ul></li><li><span><a href=\"#Load-saved-preds\" data-toc-modified-id=\"Load-saved-preds-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Load saved preds</a></span><ul class=\"toc-item\"><li><span><a href=\"#Create-CSV-of-all-preds\" data-toc-modified-id=\"Create-CSV-of-all-preds-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Create CSV of all preds</a></span></li></ul></li><li><span><a href=\"#Overall-MSE,-$R^2$,-$r^2$,-rank-corr\" data-toc-modified-id=\"Overall-MSE,-$R^2$,-$r^2$,-rank-corr-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Overall MSE, $R^2$, $r^2$, rank-corr</a></span><ul class=\"toc-item\"><li><span><a href=\"#Individual-model-results\" data-toc-modified-id=\"Individual-model-results-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Individual model results</a></span></li><li><span><a href=\"#Model-Similarity-Heatmaps\" data-toc-modified-id=\"Model-Similarity-Heatmaps-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Model Similarity Heatmaps</a></span></li><li><span><a href=\"#Cumulative-analysis\" data-toc-modified-id=\"Cumulative-analysis-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Cumulative analysis</a></span></li></ul></li><li><span><a href=\"#Break-down-by-country,-urban/rural\" data-toc-modified-id=\"Break-down-by-country,-urban/rural-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Break-down by country, urban/rural</a></span></li><li><span><a href=\"#$r^2$-over-all-countries\" data-toc-modified-id=\"$r^2$-over-all-countries-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>$r^2$ over all countries</a></span></li><li><span><a href=\"#Break-down-by-country-year,-urban/rural\" data-toc-modified-id=\"Break-down-by-country-year,-urban/rural-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Break-down by country-year, urban/rural</a></span></li><li><span><a href=\"#Urban/rural\" data-toc-modified-id=\"Urban/rural-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Urban/rural</a></span><ul class=\"toc-item\"><li><span><a href=\"#By-Country\" data-toc-modified-id=\"By-Country-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>By Country</a></span></li></ul></li><li><span><a href=\"#Model-performance-as-function-of-NL\" data-toc-modified-id=\"Model-performance-as-function-of-NL-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Model performance as function of NL</a></span><ul class=\"toc-item\"><li><span><a href=\"#When-NL-=-0\" data-toc-modified-id=\"When-NL-=-0-9.1\"><span class=\"toc-item-num\">9.1&nbsp;&nbsp;</span>When NL = 0</a></span></li><li><span><a href=\"#Predictions-vs.-NL-mean\" data-toc-modified-id=\"Predictions-vs.-NL-mean-9.2\"><span class=\"toc-item-num\">9.2&nbsp;&nbsp;</span>Predictions vs. NL mean</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import itertools\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('../')\n",
    "from batchers import dataset_constants\n",
    "from utils.analysis import (\n",
    "    calc_score,\n",
    "    chunk_vs_score,\n",
    "    evaluate_df,\n",
    "    plot_chunk_vs_score,\n",
    "    plot_label_vs_score,\n",
    "    plot_percdata_vs_score,\n",
    "    sorted_scores)\n",
    "from utils.general import colordisplay, load_npz\n",
    "from utils.plot import scatter_preds, symmetric_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGS_ROOT_DIR = '../logs/'\n",
    "DATASET_NAME = '2009-17'\n",
    "\n",
    "MODEL_NAME_TO_DIR = {\n",
    "    # KNN\n",
    "    'KNN NL mean scalar': 'dhs_knn/incountry_nlmean_scalar',\n",
    "    # 'KNN NL center scalar': 'dhs_knn/incountry_nlcenter_scalar',\n",
    "    # 'KNN NL hist': 'dhs_knn/incountry_nl_hist',\n",
    "\n",
    "    # GBT\n",
    "    'GBT NL mean scalar': 'dhs_gbt/nls_mean',\n",
    "\n",
    "    # Ridge\n",
    "    'Ridge NL mean scalar': 'dhs_ridge/incountry_nlmean_scalar',\n",
    "    # 'Ridge NL center scalar': 'dhs_ridge/incountry_nlcenter_scalar',\n",
    "    'Ridge RGB hist': 'dhs_ridge/incountry_rgb_hist',\n",
    "    'Ridge MS hist': 'dhs_ridge/incountry_ms_hist',\n",
    "    'Ridge NL hist': 'dhs_ridge/incountry_nl_hist',\n",
    "    'Ridge RGB+NL hist': 'dhs_ridge/incountry_rgbnl_hist',\n",
    "    'Ridge MS+NL hist': 'dhs_ridge/incountry_msnl_hist',\n",
    "\n",
    "    # Resnet\n",
    "    'Resnet-18 MS': 'dhs_resnet/incountry_ms',\n",
    "    'Resnet-18 MS+NL concat': 'dhs_resnet/incountry_msnl_concat',\n",
    "    'Resnet-18 NL': 'dhs_resnet/incountry_nl',\n",
    "\n",
    "    # Transfer\n",
    "    'Resnet-18 RGB Transfer': 'dhs_resnet/incountry_rgb_transfer',\n",
    "    'Resnet-18 MS Transfer': 'dhs_resnet/incountry_ms_transfer',\n",
    "}\n",
    "\n",
    "MODEL_NAMES = sorted(MODEL_NAME_TO_DIR.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Saved Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load `labels`, `locs`, and `years`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz = load_npz('../data/dhs_image_hists.npz')\n",
    "\n",
    "labels = npz['labels']\n",
    "locs = npz['locs']\n",
    "years = npz['years']\n",
    "nls_center = npz['nls_center']\n",
    "nls_mean = npz['nls_mean']\n",
    "\n",
    "num_examples = len(labels)\n",
    "assert np.all(np.asarray([len(labels), len(locs), len(years), len(nls_center), len(nls_mean)]) == num_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load `loc_dict`\n",
    "\n",
    "`loc_dict` has the format:\n",
    "```python\n",
    "{\n",
    "    (lat, lon): {\n",
    "        'cluster': 1,\n",
    "        'country': 'malawi',\n",
    "        'country_year': 'malawi_2012',  # surveyID\n",
    "        'households': 25,\n",
    "        'urban': False,\n",
    "        'wealth': -0.513607621192932,\n",
    "        'wealthpooled': -0.732255101203918,\n",
    "        'year': 2012\n",
    "    }, ...\n",
    "}\n",
    "```\n",
    "\n",
    "NOTE: `year` and `country_year` might differ in the year. `country_year` is the survey ID, which says which year the survey started. However, sometimes the DHS surveys cross the year-boundary, in which case `country_year` will remain the same but `year` will be the next year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_dict_path = '../data/dhs_loc_dict.pkl'\n",
    "with open(loc_dict_path, 'rb') as f:\n",
    "    loc_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get urban v. rural indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urban_rural_indices(locs, loc_dict):\n",
    "    '''\n",
    "    Args\n",
    "    - locs: np.array, shape [N, 2]\n",
    "    - loc_dict: dict, (lat, lon) => dict\n",
    "\n",
    "    Returns\n",
    "    - urban_indices: np.array, shape [num_urban]\n",
    "    - rural_indices: np.array, shape [num_rural]\n",
    "    '''\n",
    "    urban_indices = []\n",
    "    rural_indices = []\n",
    "\n",
    "    for i, loc in enumerate(locs):\n",
    "        loc = tuple(loc)\n",
    "        if loc_dict[loc]['urban'] == 0:\n",
    "            rural_indices.append(i)\n",
    "        else:\n",
    "            urban_indices.append(i)\n",
    "    urban_indices = np.asarray(urban_indices)\n",
    "    rural_indices = np.asarray(rural_indices)\n",
    "    print(f'num urban: {len(urban_indices)}\\t num rural: {len(rural_indices)}')\n",
    "    return urban_indices, rural_indices\n",
    "\n",
    "urban_indices, rural_indices = get_urban_rural_indices(locs, loc_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `country_indices` and `country_labels`\n",
    "\n",
    "`country_indices` is a dictionary that maps a country name to a sorted `np.array` of its indices\n",
    "```python\n",
    "{ 'malawi': np.array([ 8530,  8531,  8532, ..., 10484, 10485, 10486]), ... }\n",
    "```\n",
    "\n",
    "`country_labels` is a `np.array` that shows which country each example belongs to\n",
    "```python\n",
    "np.array([0, 0, 0, 0, ..., 22, 22, 22])\n",
    "```\n",
    "where countries are indexed by their position in `dataset_constants.DHS_COUNTRIES`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_indices = defaultdict(list)  # country => np.array of indices\n",
    "country_labels = np.zeros(num_examples, dtype=np.int32)  # np.array of country labels\n",
    "\n",
    "for i, loc in enumerate(locs):\n",
    "    country = loc_dict[tuple(loc)]['country']\n",
    "    country_indices[country].append(i)\n",
    "\n",
    "for i, country in enumerate(dataset_constants.DHS_COUNTRIES):\n",
    "    country_indices[country] = np.asarray(country_indices[country])\n",
    "    indices = country_indices[country]\n",
    "    country_labels[indices] = i\n",
    "\n",
    "country_indices['overall'] = np.arange(num_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load saved preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = {}\n",
    "\n",
    "for model_name, model_dir in MODEL_NAME_TO_DIR.items():\n",
    "    print(model_name)\n",
    "    npz_path = os.path.join(LOGS_ROOT_DIR, model_dir, 'test_preds.npz')\n",
    "    preds[model_name] = load_npz(npz_path)['test_preds']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create CSV of all preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = pd.DataFrame(\n",
    "    columns=['lat', 'lon', 'country', 'year', 'urban', 'label'] + MODEL_NAMES)\n",
    "preds_df['lat'] = locs[:, 0]\n",
    "preds_df['lon'] = locs[:, 1]\n",
    "preds_df['label'] = labels\n",
    "preds_df['year'] = years\n",
    "preds_df['country'] = np.asarray(dataset_constants.DHS_COUNTRIES)[country_labels]\n",
    "preds_df.loc[:, 'urban'] = False\n",
    "preds_df.loc[urban_indices, 'urban'] = True\n",
    "\n",
    "for model_name in MODEL_NAMES:\n",
    "    preds_df[model_name] = preds[model_name]\n",
    "\n",
    "preds_df.to_csv('dhs_incountry_preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', 8):\n",
    "    display(preds_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall MSE, $R^2$, $r^2$, rank-corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_df = evaluate_df(preds_df, cols=MODEL_NAMES)\n",
    "overall_df.sort_values(by='r2', ascending=False, inplace=True)\n",
    "colordisplay(overall_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in MODEL_NAMES:\n",
    "    model_preds = preds[model_name]\n",
    "    scatter_preds(\n",
    "        labels=labels,\n",
    "        preds=model_preds,\n",
    "        title=model_name,\n",
    "        figsize=(4, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Similarity Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names_by_mse = overall_df.sort_values(by='mse').index\n",
    "num_models = len(preds)\n",
    "\n",
    "r2_mat = np.eye(num_models, dtype=np.float64)\n",
    "rank_mat = np.eye(num_models, dtype=np.float64)\n",
    "\n",
    "for i, j in itertools.combinations(range(num_models), r=2):\n",
    "    model_name1 = model_names_by_mse[i]\n",
    "    model_name2 = model_names_by_mse[j]\n",
    "\n",
    "    m1_preds = preds[model_name1]\n",
    "    m2_preds = preds[model_name2]\n",
    "\n",
    "    r2_mat[i, j] = calc_score(m1_preds, m2_preds, metric='r2')\n",
    "    rank_mat[i, j] = calc_score(m1_preds, m2_preds, metric='rank')\n",
    "    r2_mat[j, i] = r2_mat[i, j]\n",
    "    rank_mat[j, i] = rank_mat[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symmetric_heatmap(r2_mat, labels=model_names_by_mse, format_spec='{:.2f}', title='test r^2')\n",
    "symmetric_heatmap(rank_mat, labels=model_names_by_mse, format_spec='{:.2f}', title='test rank corr.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model_indices, ridge_model_names = [], []\n",
    "resnet_model_indices, resnet_model_names = [], []\n",
    "\n",
    "for i, model_name in enumerate(model_names_by_mse):\n",
    "    if 'Resnet' not in model_name:\n",
    "        ridge_model_indices.append(i)\n",
    "        ridge_model_names.append(model_name)\n",
    "    elif 'Resnet' in model_name:\n",
    "        resnet_model_indices.append(i)\n",
    "        resnet_model_names.append(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_r2s = np.zeros([len(model_names_by_mse), 5])\n",
    "for i, model_name in enumerate(model_names_by_mse):\n",
    "    chunk_r2s[i, :] = chunk_vs_score(preds=preds[model_name], labels=labels, nchunks=5, metric='r2')\n",
    "\n",
    "plot_chunk_vs_score(scores=chunk_r2s[ridge_model_indices], figsize=(6, 3),\n",
    "                    legends=ridge_model_names, metric='r2')\n",
    "\n",
    "plot_chunk_vs_score(scores=chunk_r2s[resnet_model_indices], figsize=(6, 3),\n",
    "                    legends=resnet_model_names, metric='r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmsp_mask = years < 2012\n",
    "viirs_mask = ~dmsp_mask\n",
    "\n",
    "for name, mask in [('DMSP', dmsp_mask), ('VIIRS', viirs_mask)]:\n",
    "    chunk_r2s = np.zeros([len(model_names_by_mse), 5])\n",
    "    chunk_R2s = np.zeros([len(model_names_by_mse), 5])\n",
    "    for i, model_name in enumerate(model_names_by_mse):\n",
    "        chunk_r2s[i, :] = chunk_vs_score(labels=labels[mask], preds=preds[model_name][mask], nchunks=5,\n",
    "                                         metric='r2', chunk_value=nls_mean[mask])\n",
    "        chunk_R2s[i, :] = chunk_vs_score(labels=labels[mask], preds=preds[model_name][mask], nchunks=5,\n",
    "                                         metric='R2', chunk_value=nls_mean[mask])\n",
    "\n",
    "    plot_chunk_vs_score(scores=chunk_r2s, legends=overall_df.index, metric='r2',\n",
    "                        figsize=(10, 3), cmap='tab20', xlabel=f'chunk of increasing NL mean ({name})')\n",
    "    plot_chunk_vs_score(scores=chunk_R2s, legends=overall_df.index, metric='R2',\n",
    "                        figsize=(10, 3), cmap='tab20', xlabel=f'chunk of increasing NL mean ({name})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_r2s = np.zeros([len(model_names_by_mse), num_examples])\n",
    "\n",
    "for i, model_name in enumerate(model_names_by_mse):\n",
    "    r2s, labels_sorted = sorted_scores(\n",
    "        preds=preds[model_name], labels=labels, metric='r2', sort='increasing')\n",
    "    cumulative_r2s[i, :] = r2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_r2_df = pd.DataFrame(\n",
    "    data=cumulative_r2s.T,\n",
    "    index=pd.Index(np.sort(labels), name='wealthpooled'),\n",
    "    columns=model_names_by_mse)\n",
    "with pd.option_context('display.max_rows', 4):\n",
    "    display(cumulative_r2_df)\n",
    "\n",
    "cumulative_r2_df.to_csv('dhs_incountry_cumulative_r2.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_percdata_vs_score(\n",
    "    scores_list=cumulative_r2s[ridge_model_indices],\n",
    "    legends=ridge_model_names,\n",
    "    metric='r2',\n",
    "    sort='increasing')\n",
    "\n",
    "plot_percdata_vs_score(\n",
    "    scores_list=cumulative_r2s[resnet_model_indices],\n",
    "    legends=resnet_model_names,\n",
    "    metric='r2',\n",
    "    sort='increasing')\n",
    "\n",
    "plot_label_vs_score(\n",
    "    scores_list=cumulative_r2s[ridge_model_indices],\n",
    "    labels_list=[np.sort(labels)] * len(ridge_model_indices),\n",
    "    legends=ridge_model_names,\n",
    "    metric='r2',\n",
    "    sort='increasing')\n",
    "\n",
    "plot_label_vs_score(\n",
    "    scores_list=cumulative_r2s[resnet_model_indices],\n",
    "    labels_list=[np.sort(labels)] * len(resnet_model_indices),\n",
    "    legends=resnet_model_names,\n",
    "    metric='r2',\n",
    "    sort='increasing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Break-down by country, urban/rural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df = (\n",
    "    preds_df\n",
    "    .groupby('country')\n",
    "    .apply(evaluate_df, cols=MODEL_NAMES, index_name='model'))\n",
    "country_urban_df = (\n",
    "    preds_df\n",
    "    .groupby(['country', 'urban'])\n",
    "    .apply(evaluate_df, cols=MODEL_NAMES, index_name='model'))\n",
    "\n",
    "with pd.option_context('display.max_rows', 4, 'display.precision', 3):\n",
    "    display(country_df)\n",
    "    display(country_urban_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $r^2$ over all countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean and median r^2 across countries\n",
    "country_r2_df = country_df['r2'].unstack('model')\n",
    "colordisplay(country_r2_df.describe().T)\n",
    "\n",
    "print('urban:')\n",
    "colordisplay(country_urban_df['r2'].unstack('model').loc[(slice(None), True), :].describe().T)\n",
    "\n",
    "print('rural:')\n",
    "colordisplay(country_urban_df['r2'].unstack('model').loc[(slice(None), False), :].describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_r2(x):\n",
    "    '''\n",
    "    Args\n",
    "    - x: pd.Series, index is (country, metric), value is score\n",
    "\n",
    "    Returns:\n",
    "    - y: float\n",
    "    '''\n",
    "    y = np.sum([\n",
    "        x[country] * len(country_indices[country]) / len(labels)\n",
    "        for country in x.index.get_level_values(0)\n",
    "    ])\n",
    "    return y\n",
    "\n",
    "median_r2s = country_r2_df.median(axis=0).rename('median r2')\n",
    "mean_r2s = country_r2_df.mean(axis=0).rename('mean r2')\n",
    "weighted_r2s = country_r2_df.apply(weighted_r2, axis=0).rename('weighted r2')\n",
    "overall_r2s = overall_df.loc[MODEL_NAMES, 'r2'].rename('overall r2')\n",
    "\n",
    "agg_r2s = pd.concat([weighted_r2s, median_r2s, mean_r2s, overall_r2s], axis=1)\n",
    "agg_r2s.sort_values(by='weighted r2', ascending=False, inplace=True)\n",
    "colordisplay(agg_r2s)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "agg_r2s.T.plot(kind='bar', ax=ax, width=0.9, colormap='tab20')\n",
    "plt.setp(ax.get_xticklabels(), rotation=0, ha='center',\n",
    "         rotation_mode='anchor')\n",
    "ax.set_ylabel('r^2')\n",
    "ax.set_title('Incountry r^2 on test countries')\n",
    "ax.grid(True, axis='y')\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_country_performance(df, model_names, title, xlabel):\n",
    "    '''\n",
    "    Args\n",
    "    - df: pd.DataFrame, df.loc[country, model_name] gives model performance on a particular country\n",
    "    - model_names: list of str\n",
    "    - title: str\n",
    "    - xlabel: str\n",
    "    '''\n",
    "    CMAP_FN = plt.cm.get_cmap('tab20')\n",
    "    COUNTRY_YEAR_COLORS = [CMAP_FN.colors[i % 20] for i in range(len(dataset_constants.DHS_COUNTRIES))]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 5))\n",
    "\n",
    "    for i, country in enumerate(dataset_constants.DHS_COUNTRIES):\n",
    "        r2s = df.loc[country, model_names]\n",
    "        size = len(country_indices[country]) / len(labels) * 1000\n",
    "        ax.scatter(x=r2s, y=model_names, s=size, c=[COUNTRY_YEAR_COLORS[i]], label=country)\n",
    "\n",
    "    ax.invert_yaxis()  # invert direction to put best-performing models at the top\n",
    "    ax.grid(True)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_country_performance(\n",
    "    df=country_r2_df,\n",
    "    model_names=list(agg_r2s.index),\n",
    "    title='Incountry Test Performance',\n",
    "    xlabel='test r^2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Break-down by country-year, urban/rural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countryyear_df = (\n",
    "    preds_df\n",
    "    .groupby(['country', 'year'])\n",
    "    .apply(evaluate_df, cols=MODEL_NAMES, index_name='model'))\n",
    "countryyear_urban_df = (\n",
    "    preds_df\n",
    "    .groupby(['country', 'year', 'urban'])\n",
    "    .apply(evaluate_df, cols=MODEL_NAMES, index_name='model'))\n",
    "\n",
    "with pd.option_context('display.max_rows', 4, 'display.precision', 3):\n",
    "    display(countryyear_df)\n",
    "    display(countryyear_urban_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean and median r^2 across country_years\n",
    "countryyear_r2_df = countryyear_df['r2'].unstack('model')\n",
    "colordisplay(countryyear_r2_df.describe().T)\n",
    "\n",
    "print('urban:')\n",
    "colordisplay(countryyear_urban_df['r2'].unstack('model').loc[(slice(None), slice(None), True), :].describe().T)\n",
    "\n",
    "print('rural:')\n",
    "colordisplay(countryyear_urban_df['r2'].unstack('model').loc[(slice(None), slice(None), False), :].describe().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Urban/rural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urban_rural_df = (\n",
    "    preds_df\n",
    "    .groupby('urban')\n",
    "    .apply(evaluate_df, cols=MODEL_NAMES, index_name='model')\n",
    "    .unstack('urban'))\n",
    "\n",
    "with pd.option_context('display.max_rows', 20, 'display.precision', 3):\n",
    "    display(urban_rural_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = urban_rural_df.loc[:, ('r2', slice(None))].plot(\n",
    "    kind='bar', figsize=[10, 5])\n",
    "ax.set_ylabel('test $r^2$ on urban/rural')\n",
    "ax.set_ylim(bottom=0, top=0.5)\n",
    "ax.set_title('Model performance ($r^2$) on urban vs. rural')\n",
    "ax.grid(True, axis='y')\n",
    "# Rotate the tick labels and set their alignment.\n",
    "plt.setp(ax.get_xticklabels(), rotation=60, ha='right',\n",
    "         rotation_mode='anchor')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = urban_rural_df.loc[:, ('R2', slice(None))].plot(\n",
    "    kind='bar', figsize=[10, 5])\n",
    "ax.set_ylabel('test $R^2$ on urban/rural')\n",
    "ax.set_ylim(bottom=0, top=0.5)\n",
    "ax.set_title('Model performance ($R^2$) on urban vs. rural')\n",
    "ax.grid(True, axis='y')\n",
    "# Rotate the tick labels and set their alignment.\n",
    "plt.setp(ax.get_xticklabels(), rotation=60, ha='right',\n",
    "         rotation_mode='anchor')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_urban_rural_predictions(labels, preds, urban_indices, rural_indices):\n",
    "    '''\n",
    "    Args\n",
    "    - labels: np.array, shape [N]\n",
    "    - preds: dict, model_name => np.array, shape [N]\n",
    "    - urban_indices: np.array, shape [num_urban]\n",
    "    - rural_indices: np.array, shape [num_rural]\n",
    "    '''\n",
    "    nrows = int(np.ceil(np.sqrt(len(preds))))\n",
    "    ncols = int(np.ceil(len(preds) / nrows))\n",
    "    fig, axs = plt.subplots(nrows=nrows, ncols=ncols,\n",
    "                            sharey=False, sharex=False, figsize=[ncols*3, nrows*3])\n",
    "    for model_name, ax in zip(preds, axs.flat):\n",
    "        ax.scatter(\n",
    "            x=labels[urban_indices],\n",
    "            y=preds[model_name][urban_indices],\n",
    "            s=2, label='urban')\n",
    "        ax.scatter(\n",
    "            x=labels[rural_indices],\n",
    "            y=preds[model_name][rural_indices],\n",
    "            s=2, label='rural')\n",
    "        ax.grid(True)\n",
    "        ax.set_aspect('equal')\n",
    "        ax.set(xlabel='label', ylabel='pred', title=model_name)\n",
    "        xy_line = np.array([-2, 3])\n",
    "        ax.plot(xy_line, xy_line, color='black')\n",
    "        ax.legend()\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_urban_rural_predictions(labels, preds, urban_indices, rural_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_country_performance(\n",
    "    df=country_urban_df['r2'].unstack('model').loc[(slice(None), True), :],\n",
    "    model_names=MODEL_NAMES,\n",
    "    title='Incountry Test Performance on Urban',\n",
    "    xlabel='test $r^2$')\n",
    "\n",
    "plot_country_performance(\n",
    "    df=country_urban_df['r2'].unstack('model').loc[(slice(None), False), :],\n",
    "    model_names=MODEL_NAMES,\n",
    "    title='Incountry Test Performance on Rural',\n",
    "    xlabel='test $r^2$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model performance as function of NL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When NL = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batchers.batcher import MEANS_DICT, STD_DEVS_DICT\n",
    "\n",
    "dmsp0 = (0.0 - MEANS_DICT[DATASET_NAME]['DMSP']) / STD_DEVS_DICT[DATASET_NAME]['DMSP']\n",
    "viirs0 = (0.0 - MEANS_DICT[DATASET_NAME]['VIIRS']) / STD_DEVS_DICT[DATASET_NAME]['VIIRS']\n",
    "\n",
    "print('DMSP 0-value (after normalization):', dmsp0)\n",
    "print('VIIRS 0-value (after normalization):', viirs0)\n",
    "\n",
    "dmsp0_indices = (years < 2012) & (nls_mean == dmsp0)\n",
    "viirs0_indices = (years >= 2012) & (nls_mean == viirs0)\n",
    "nl0_indices = dmsp0_indices | viirs0_indices\n",
    "\n",
    "assert np.all(nls_mean[nl0_indices] == dmsp0)\n",
    "assert np.all(nls_center[nl0_indices] == dmsp0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# of locs w/ DMSP=0:', np.sum(dmsp0_indices))\n",
    "print('# of locs w/ VIIRS=0:', np.sum(viirs0_indices))\n",
    "print('# of locs w/ NL=0:', np.sum(nl0_indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we train a separate ridge regression model for each left-out test country, we get many different predictions for when NL = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique(preds['Resnet-18 NL'][nl0_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_preds_nl0(model_name, labels, preds, nl0_indices):\n",
    "    '''\n",
    "    Args\n",
    "    - model_name: str\n",
    "    - labels: np.array, shape [num_examples]\n",
    "    - preds: np.array, shape [num_examples]\n",
    "    - nl0_indices: np.array, integer indices into labels/preds\n",
    "    '''\n",
    "    fig, ax = plt.subplots(1, 1, figsize=[4, 4])\n",
    "    ax.scatter(x=labels, y=preds, s=2)\n",
    "    ax.scatter(x=labels[nl0_indices], y=preds[nl0_indices], c='red', s=2, label='NL = 0')\n",
    "    ax.set(xlabel='label', ylabel='pred', title=model_name)\n",
    "    ax.grid(True)\n",
    "    ax.set_aspect('equal')\n",
    "    xy_line = np.array([-1.5, 3])\n",
    "    ax.plot(xy_line, xy_line, color='black')\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for model_name in MODEL_NAME_TO_DIR:\n",
    "    plot_preds_nl0(model_name, labels, preds[model_name], nl0_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl0_df = evaluate_df(preds_df.loc[nl0_indices, :], cols=MODEL_NAMES)\n",
    "nl0_df.sort_values('r2', ascending=False, inplace=True)\n",
    "display(nl0_df.style.format('{:.3f}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions vs. NL mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_preds_v_nl(model_name, preds, nl_means):\n",
    "    '''\n",
    "    Args\n",
    "    - model_name: str\n",
    "    - preds: np.array\n",
    "    - nl_means: np.array\n",
    "    '''\n",
    "    fig, ax = plt.subplots(1, 1, figsize=[5, 5])\n",
    "    ax.scatter(x=nl_means, y=preds, s=3)\n",
    "    ax.set_title(model_name)\n",
    "    ax.set_xlabel('Mean NL of Image (std dev from mean)')\n",
    "    ax.set_ylabel('Predicted Wealthpooled')\n",
    "    ax.grid(True)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_residuals_v_nl(model_name, preds, labels, nl_means):\n",
    "    '''\n",
    "    Args\n",
    "    - model_name: str\n",
    "    - preds: np.array\n",
    "    - labels: np.array\n",
    "    - nl_means: np.array\n",
    "    '''\n",
    "    residuals = labels - preds\n",
    "    fig, ax = plt.subplots(1, 1, figsize=[5, 5])\n",
    "    ax.scatter(x=nl_means, y=residuals, s=3)\n",
    "    ax.set_title(model_name)\n",
    "    ax.set_xlabel('Mean NL of Image (std dev from mean)')\n",
    "    ax.set_ylabel('Residual (label - pred)')\n",
    "    ax.grid(True)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in MODEL_NAME_TO_DIR:\n",
    "    plot_preds_v_nl(model_name, preds[model_name], nls_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in MODEL_NAME_TO_DIR:\n",
    "    plot_residuals_v_nl(model_name, preds[model_name], labels, nls_mean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "239.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
